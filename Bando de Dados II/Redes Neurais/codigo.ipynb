{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais na Análise de Sentimentos do IMDB\n",
    "### Trabalho de Áleks Sebastian de Freitas Araújo, André Ferreira Santana, Dayan Freitas Alves,Douglas Moura Araújo, Lucas Aguiar dos Santos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lembre-se de instalar todas as dependências necessárias usando %pip install [Nome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Análise de Sentimento via Pipeline, Agrupamento e Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from transformers import pipeline\n",
    "from IPython.display import HTML, display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar a base de dados\n",
    "\n",
    "df = pd.read_csv(\"IMDB_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa de Limpeza\n",
    "\n",
    "df['Director'] = df['Director'].replace('sEthan CoenJoel Coen','Coen Brothers')\\\n",
    "                                 .replace('sJoel CoenEthan Coen','Coen Brothers')\n",
    "df['Release Year'] = df['Release Year'].apply(pd.to_numeric)\n",
    "\n",
    "df['Length'] = df['Length'].apply(lambda x: int(x.split('h')[0])*60 + int(x.split(' ')[-1].replace('m',''))\n",
    "                                    if isinstance(x, str) and 'm' in str(x)\n",
    "                                    else int(x.split('h')[0])*60 if isinstance(x, str)\n",
    "                                    else None)\n",
    "\n",
    "def ast_(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df['Cast'] = df['Cast'].apply(lambda x: ast_(x))\n",
    "df['Votes'] = df['Votes'].str.replace(',', '').apply(pd.to_numeric, errors='coerce')\n",
    "df['Gross'] = df['Gross'].apply(lambda x: float(x.replace('$','').replace('M',''))*10**6 \n",
    "                                if 'M' in str(x) else None)\n",
    "df['IMDB Rating'] = pd.to_numeric(df['IMDB Rating'], errors='coerce')\n",
    "df['Rating By User'] = df['Rating By User'].apply(lambda x: int(x.split('/')[0]) \n",
    "                                                  if isinstance(x, str) else None)\n",
    "df['Review Date'] = pd.to_datetime(df['Review Date'], errors='coerce')\n",
    "\n",
    "# Garantir que a coluna de reviews não tenha valores nulos\n",
    "df['Review Text'] = df['Review Text'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a pipeline de análise de sentimentos usando o modelo que retorna ratings em estrelas\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "def process_reviews_in_batches(reviews, batch_size=64):\n",
    "    \"\"\"\n",
    "    Processa a lista de reviews em batches usando a pipeline, com truncation para 512 tokens.\n",
    "    Retorna uma lista com os resultados.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    n = len(reviews)\n",
    "    for i in range(0, n, batch_size):\n",
    "        batch = reviews[i:i+batch_size]\n",
    "        try:\n",
    "            batch_results = sentiment_pipeline(batch, truncation=True, max_length=512, batch_size=batch_size)\n",
    "        except Exception as e:\n",
    "            batch_results = [None] * len(batch)\n",
    "        results.extend(batch_results)\n",
    "        print(f\"Processados {min(i+batch_size, n)}/{n} reviews\", end='\\r')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados\n",
    "\n",
    "# Converter os reviews para uma lista\n",
    "reviews = df['Review Text'].tolist()\n",
    "\n",
    "# Processar toda a base em batches\n",
    "batch_results = process_reviews_in_batches(reviews, batch_size=64)\n",
    "\n",
    "def extract_rating(result):\n",
    "    \"\"\"\n",
    "    Extrai a nota (1 a 5) do label retornado, que vem no formato \"X stars\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(result[\"label\"][0])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Criar nova coluna com o rating de sentimento\n",
    "df[\"Sentiment Rating\"] = [extract_rating(res) if res is not None else None for res in batch_results]\n",
    "\n",
    "# Agrupar por Poster e Title para calcular a média do IMDB e do Sentiment Rating\n",
    "g = df.groupby([\"Poster\", \"Title\"]).agg({\"IMDB Rating\": \"mean\", \"Sentiment Rating\": \"mean\"}).reset_index()\n",
    "\n",
    "# Mesclar informação do Release Year (utilizando linhas únicas)\n",
    "g = g.merge(df.drop_duplicates(subset=[\"Poster\", \"Title\", \"Release Year\"])[[\"Poster\", \"Title\", \"Release Year\"]],\n",
    "            on=[\"Poster\", \"Title\"], how=\"left\")\n",
    "\n",
    "# Ordenar os filmes pelo Sentiment Rating de forma decrescente\n",
    "g = g.sort_values(\"Sentiment Rating\", ascending=False)\n",
    "g = g[[\"Poster\", \"Title\", \"Release Year\", \"IMDB Rating\", \"Sentiment Rating\"]]\n",
    "\n",
    "# Converter a coluna 'Poster' para HTML para exibir as imagens (em ambiente Jupyter)\n",
    "g[\"Poster\"] = g.apply(lambda x: f'<img src=\"{x[\"Poster\"]}\" style=\"max-height:300px;max-width:300px;\">', axis=1)\n",
    "\n",
    "# Aplicar um background gradient para realçar as colunas numéricas\n",
    "g = g.style.background_gradient(subset=[\"IMDB Rating\", \"Sentiment Rating\"], cmap=\"Reds\")\n",
    "\n",
    "# Exibir a tabela formatada\n",
    "display(HTML(g.to_html(escape=False)))\n",
    "\n",
    "# Plotar distribuições dos ratings de sentimento e dos ratings IMDB\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "df[\"Sentiment Rating\"].dropna().hist(bins=20, ax=ax1, color=\"skyblue\", edgecolor=\"black\")\n",
    "ax1.set_title(\"Distribuição dos Ratings de Sentimento\")\n",
    "ax1.set_xlabel(\"Rating de Sentimento (1 a 5)\")\n",
    "ax1.set_ylabel(\"Frequência\")\n",
    "\n",
    "df[\"IMDB Rating\"].dropna().hist(bins=20, ax=ax2, color=\"salmon\", edgecolor=\"black\")\n",
    "ax2.set_title(\"Distribuição dos Ratings IMDB\")\n",
    "ax2.set_xlabel(\"Rating IMDB\")\n",
    "ax2.set_ylabel(\"Frequência\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Clustering com TF-IDF, K-Means e PCA (Método Clássico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupamento de Reviews com K-Means e Visualização com PCA\n",
    "\n",
    "# Vetorização TF-IDF dos textos dos reviews\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"Review Text\"])\n",
    "\n",
    "# Aplicar K-Means para agrupar em 3 clusters\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df[\"Cluster\"] = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Reduzir a dimensionalidade para 2 componentes com PCA para visualização\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca_result = pca.fit_transform(tfidf_matrix.toarray())\n",
    "df[\"PCA1\"] = pca_result[:, 0]\n",
    "df[\"PCA2\"] = pca_result[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados\n",
    "\n",
    "# Plotar os clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = plt.cm.Paired(np.linspace(0, 1, k))\n",
    "for cluster in range(k):\n",
    "    cluster_data = df[df[\"Cluster\"] == cluster]\n",
    "    plt.scatter(cluster_data[\"PCA1\"], cluster_data[\"PCA2\"], color=colors[cluster], label=f\"Cluster {cluster}\")\n",
    "plt.title(\"K-Means Clustering dos Reviews\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame com os clusters adicionados\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Classificação de Sentimentos Usando Redes Neurais (Embeddings com DistilBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas utilizadas\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de Categorias de Sentimento, Balanceamento de Classes e Geração de Embeddings com DistilBERT\n",
    "\n",
    "# Se a coluna \"Sentiment Category\" não existir, cria-a a partir de \"Rating By User\"\n",
    "def bin_sentiment(rating):\n",
    "    if rating < 4:\n",
    "        return \"negative\"\n",
    "    elif rating <= 6:\n",
    "        return \"neutral\"\n",
    "    else:\n",
    "        return \"positive\"\n",
    "\n",
    "df = df.dropna(subset=[\"Rating By User\"])\n",
    "if \"Sentiment Category\" not in df.columns:\n",
    "    df[\"Sentiment Category\"] = df[\"Rating By User\"].apply(bin_sentiment)\n",
    "\n",
    "# Balanceamento das Classes\n",
    "n_samples = 2500\n",
    "df_neg = df[df[\"Sentiment Category\"] == \"negative\"].sample(n_samples, random_state=42)\n",
    "df_neu = df[df[\"Sentiment Category\"] == \"neutral\"].sample(n_samples, random_state=42)\n",
    "df_pos = df[df[\"Sentiment Category\"] == \"positive\"].sample(n_samples, random_state=42)\n",
    "df_balanced = pd.concat([df_neg, df_neu, df_pos]).reset_index(drop=True)\n",
    "print(\"Distribuição das Classes Após Balanceamento:\")\n",
    "print(df_balanced[\"Sentiment Category\"].value_counts())\n",
    "\n",
    "# Gerar Embeddings dos Reviews Usando DistilBERT\n",
    "tokenizer_nn = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model_nn_emb = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    encoded_input = tokenizer_nn(text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model_nn_emb(**encoded_input)\n",
    "    # Utilizar o embedding do token [CLS] (primeiro token)\n",
    "    cls_embedding = model_output.last_hidden_state[:, 0, :]\n",
    "    return cls_embedding.squeeze().numpy()\n",
    "\n",
    "embeddings_list = [get_embedding(text) for text in df_balanced[\"Review Text\"].tolist()]\n",
    "embeddings = np.array(embeddings_list)\n",
    "\n",
    "# Mapear as classes para rótulos numéricos\n",
    "mapping = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "df_balanced[\"label\"] = df_balanced[\"Sentiment Category\"].map(mapping)\n",
    "labels = df_balanced[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento e Avaliação de um Modelo Neural (MLP) para Classificação de Sentimentos\n",
    "\n",
    "# Dividir os Dados em Treino e Teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Construir o Modelo Neural (MLP) com Keras\n",
    "model_nn = models.Sequential([\n",
    "    layers.Input(shape=(embeddings.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes: negative, neutral, positive\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "model_nn.summary()\n",
    "\n",
    "# Treinar o Modelo\n",
    "history = model_nn.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Avaliar o Modelo\n",
    "loss, accuracy = model_nn.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "y_pred_probs = model_nn.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de Confusão - Neural Network\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(3)\n",
    "plt.xticks(tick_marks, [\"negative\", \"neutral\", \"positive\"], rotation=45)\n",
    "plt.yticks(tick_marks, [\"negative\", \"neutral\", \"positive\"])\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
